#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æ12ä¼ æ„Ÿå™¨æ•°æ®çš„å‹åŠ›åˆ†å¸ƒï¼Œç¡®å®šåˆç†çš„æ— äººæ£€æµ‹é˜ˆå€¼
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

def analyze_pressure_distribution():
    """åˆ†æå‹åŠ›åˆ†å¸ƒ"""
    print("ğŸ“Š åˆ†æ12ä¼ æ„Ÿå™¨æ•°æ®å‹åŠ›åˆ†å¸ƒ")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®
    import os
    script_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    data_path = os.path.join(script_dir, 'data', 'dataset_12_sensors.csv')
    df = pd.read_csv(data_path)
    
    # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æ€»å‹åŠ›
    sensor_cols = [col for col in df.columns if col.startswith('Sensor_')]
    df['total_pressure'] = df[sensor_cols].sum(axis=1)
    
    # ç»Ÿè®¡å„ç±»åˆ«çš„å‹åŠ›åˆ†å¸ƒ
    print("\nğŸ“‹ å„ç±»åˆ«å‹åŠ›ç»Ÿè®¡:")
    for label in df['Label'].unique():
        subset = df[df['Label'] == label]
        pressure_stats = subset['total_pressure'].describe()
        print(f"\n{label.upper()} ç±»åˆ«:")
        print(f"   æ ·æœ¬æ•°: {len(subset)}")
        print(f"   æœ€å°å€¼: {pressure_stats['min']:.0f} å…‹")
        print(f"   25%åˆ†ä½: {pressure_stats['25%']:.0f} å…‹") 
        print(f"   ä¸­ä½æ•°: {pressure_stats['50%']:.0f} å…‹")
        print(f"   75%åˆ†ä½: {pressure_stats['75%']:.0f} å…‹")
        print(f"   æœ€å¤§å€¼: {pressure_stats['max']:.0f} å…‹")
        print(f"   å¹³å‡å€¼: {pressure_stats['mean']:.0f} å…‹")
    
    # æ‰¾å‡ºæœ€å°çš„æœ‰æ•ˆå‹åŠ›å€¼
    min_valid_pressure = df['total_pressure'].min()
    max_valid_pressure = df['total_pressure'].max()
    
    print(f"\nğŸ¯ æ•°æ®é›†å‹åŠ›èŒƒå›´:")
    print(f"   æœ€å°æœ‰æ•ˆå‹åŠ›: {min_valid_pressure:.0f} å…‹")
    print(f"   æœ€å¤§æœ‰æ•ˆå‹åŠ›: {max_valid_pressure:.0f} å…‹")
    
    # å»ºè®®é˜ˆå€¼
    # å–æœ€å°æœ‰æ•ˆå‹åŠ›çš„80%ä½œä¸ºå®‰å…¨é˜ˆå€¼
    suggested_threshold = min_valid_pressure * 0.8
    print(f"\nğŸ’¡ å»ºè®®é˜ˆå€¼:")
    print(f"   å½“å‰é˜ˆå€¼: 500 å…‹")
    print(f"   å»ºè®®é˜ˆå€¼: {suggested_threshold:.0f} å…‹ (æœ€å°å€¼çš„80%)")
    
    # åˆ†æä½å‹åŠ›åŒºé—´
    low_pressure_samples = df[df['total_pressure'] < 2000]
    print(f"\nğŸ” ä½å‹åŠ›æ ·æœ¬åˆ†æ (<2000å…‹):")
    print(f"   æ ·æœ¬æ•°: {len(low_pressure_samples)}")
    if len(low_pressure_samples) > 0:
        print(f"   å‹åŠ›èŒƒå›´: {low_pressure_samples['total_pressure'].min():.0f} - {low_pressure_samples['total_pressure'].max():.0f} å…‹")
        print(f"   æ ‡ç­¾åˆ†å¸ƒ:")
        for label, count in low_pressure_samples['Label'].value_counts().items():
            print(f"     {label}: {count} ä¸ª")
    
    # æ£€æŸ¥éé›¶ä¼ æ„Ÿå™¨æ•°é‡
    print(f"\nğŸ” éé›¶ä¼ æ„Ÿå™¨æ•°é‡åˆ†æ:")
    df['nonzero_sensors'] = (df[sensor_cols] > 0).sum(axis=1)
    
    for label in df['Label'].unique():
        subset = df[df['Label'] == label]
        nonzero_stats = subset['nonzero_sensors'].describe()
        print(f"\n{label.upper()} ç±»åˆ«éé›¶ä¼ æ„Ÿå™¨:")
        print(f"   æœ€å°‘: {nonzero_stats['min']:.0f} ä¸ª")
        print(f"   å¹³å‡: {nonzero_stats['mean']:.1f} ä¸ª")
        print(f"   æœ€å¤š: {nonzero_stats['max']:.0f} ä¸ª")
    
    # å»ºè®®ç»¼åˆé˜ˆå€¼ç­–ç•¥
    print(f"\nğŸ¯ å»ºè®®é˜ˆå€¼ç­–ç•¥:")
    print(f"   æ–¹æ¡ˆ1 - å•ä¸€å‹åŠ›é˜ˆå€¼: {suggested_threshold:.0f} å…‹")
    print(f"   æ–¹æ¡ˆ2 - å‹åŠ›+ä¼ æ„Ÿå™¨æ•°é‡: æ€»å‹åŠ› > 1500 å…‹ ä¸” éé›¶ä¼ æ„Ÿå™¨ >= 8 ä¸ª")
    print(f"   æ–¹æ¡ˆ3 - ä¿å®ˆç­–ç•¥: æ€»å‹åŠ› > 1000 å…‹")

if __name__ == "__main__":
    analyze_pressure_distribution()

    # ================== 16x16å‹åŠ›é˜ˆå€¼è¡¨ç”Ÿæˆä¸åˆ†ç±» ==================
    import json

    def load_256_dataset(path):
        """è¯»å–16x16ä¼ æ„Ÿå™¨æ•°æ®é›†ï¼Œå‡è®¾æœ€åä¸€åˆ—ä¸ºæ ‡ç­¾"""
        df = pd.read_csv(path, header=None)
        sensor_data = df.iloc[:, :-1].values
        labels = df.iloc[:, -1].values.astype(str)
        return sensor_data, labels

    def compute_stats(sensor_data, labels):
        stats = {}
        for label in np.unique(labels):
            data = sensor_data[labels == label]
            stats[label] = {
                'mean': np.mean(data, axis=0).tolist(),
                'std': np.std(data, axis=0).tolist()
            }
        return stats

    def generate_threshold_table(stats):
        threshold_table = {}
        for i in range(len(stats['normal']['mean'])):
            threshold_table[i] = {}
            for label in stats:
                mean = stats[label]['mean'][i]
                std = stats[label]['std'][i]
                threshold_table[i][label] = [mean - std, mean + std]
        return threshold_table

    def save_threshold_table(threshold_table, path):
        with open(path, 'w') as f:
            json.dump(threshold_table, f, indent=2)

    def load_threshold_table(path):
        with open(path, 'r') as f:
            return json.load(f)

    def classify(new_data, threshold_table):
        scores = {label: 0 for label in threshold_table[0].keys()}
        for i, value in enumerate(new_data):
            for label in scores:
                low, high = threshold_table[str(i)][label]
                if low <= value <= high:
                    scores[label] += 1
        return max(scores, key=scores.get)

    def main_256():
        DATASET_PATH = 'data/dataset.csv'
        THRESHOLD_PATH = 'data/pressure_thresholds.json'
        sensor_data, labels = load_256_dataset(DATASET_PATH)
        stats = compute_stats(sensor_data, labels)
        threshold_table = generate_threshold_table(stats)
        save_threshold_table(threshold_table, THRESHOLD_PATH)
        print(f'âœ… 16x16å‹åŠ›é˜ˆå€¼è¡¨å·²ä¿å­˜åˆ° {THRESHOLD_PATH}')
        # ç¤ºä¾‹åˆ†ç±»
        # new_data = sensor_data[0]
        # threshold_table = load_threshold_table(THRESHOLD_PATH)
        # result = classify(new_data, threshold_table)
        # print('é¢„æµ‹ç±»åˆ«:', result)

    # å¦‚éœ€è¿è¡Œï¼Œå–æ¶ˆä¸‹è¡Œæ³¨é‡Š
    # main_256()