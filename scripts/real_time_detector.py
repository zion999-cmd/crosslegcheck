#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®æ—¶å‹åŠ›ä¼ æ„Ÿå™¨æ•°æ®é‡‡é›†ä¸è¯†åˆ«ç³»ç»Ÿ
ç»“åˆä¸²å£é‡‡é›†å’ŒCNNæ¨¡å‹é¢„æµ‹ï¼Œå®ç°å®æ—¶åˆ†ç±»
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
import threading
import queue
import time
from datetime import datetime
import sys
import os
import warnings
from collections import deque

# å¯¼å…¥ç°æœ‰æ¨¡å—
from serial_sensor_reader import PressureSensorReader
from cnn_augmented import pressure_to_image

warnings.filterwarnings('ignore')

class RealTimeDetector:
    """å®æ—¶æ£€æµ‹å™¨ç±»"""
    
    def __init__(self, model_path='../models/cnn_augmented_model.keras'):
        self.model_path = model_path
        self.model = None
        self.model_loaded = False
        self.class_names = ['left', 'normal', 'right']
        
        # æ•°æ®é˜Ÿåˆ—å’Œå¤„ç†
        self.data_queue = queue.Queue(maxsize=100)
        self.result_queue = queue.Queue(maxsize=50)
        
        # æ§åˆ¶æ ‡å¿—
        self.running = False
        self.sensor_thread = None
        self.detector_thread = None
        
        # ä¼ æ„Ÿå™¨è¯»å–å™¨
        self.sensor_reader = PressureSensorReader()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_samples': 0,
            'predictions': {'left': 0, 'normal': 0, 'right': 0},
            'start_time': None,
            'last_result': None,
            'confidence_history': deque(maxlen=10)
        }
    
    def load_model_async(self):
        """å¼‚æ­¥åŠ è½½æ¨¡å‹"""
        def load():
            print(f"ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
            try:
                self.model = keras.models.load_model(self.model_path)
                self.model_loaded = True
                print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
                print(f"   - æ¨¡å‹å‚æ•°é‡: {self.model.count_params():,}")
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.model_loaded = False
        
        # åœ¨åå°çº¿ç¨‹ä¸­åŠ è½½æ¨¡å‹
        model_thread = threading.Thread(target=load, daemon=True)
        model_thread.start()
        return model_thread
    
    def sensor_data_collector(self):
        """ä¼ æ„Ÿå™¨æ•°æ®æ”¶é›†çº¿ç¨‹"""
        print(f"ğŸ“¡ å¯åŠ¨æ•°æ®é‡‡é›†çº¿ç¨‹...")
        
        # è¿æ¥ä¼ æ„Ÿå™¨
        if not self.sensor_reader.connect():
            print(f"âŒ ä¼ æ„Ÿå™¨è¿æ¥å¤±è´¥")
            return
        
        print(f"âœ… ä¼ æ„Ÿå™¨è¿æ¥æˆåŠŸï¼Œå¼€å§‹æ•°æ®é‡‡é›†...")
        
        # ç­‰å¾…è¿æ¥ç¨³å®š
        time.sleep(2)
        self.sensor_reader.serial_conn.flushInput()
        self.sensor_reader.serial_conn.flushOutput()
        
        consecutive_failures = 0
        max_failures = 10
        
        while self.running:
            try:
                # è¯»å–åŸå§‹æ•°æ®
                raw_data = self.sensor_reader.read_raw_data(512)
                
                if raw_data:
                    # è§£ææ•°æ®å¸§
                    frames = self.sensor_reader.parse_hex_data(raw_data)
                    
                    if frames:
                        consecutive_failures = 0
                        for frame in frames:
                            if not self.data_queue.full():
                                timestamp = datetime.now()
                                self.data_queue.put((timestamp, frame))
                            else:
                                # é˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒæœ€æ—§çš„æ•°æ®
                                try:
                                    self.data_queue.get_nowait()
                                    self.data_queue.put((timestamp, frame))
                                except queue.Empty:
                                    pass
                    else:
                        consecutive_failures += 1
                else:
                    consecutive_failures += 1
                
                # æ£€æŸ¥è¿ç»­å¤±è´¥æ¬¡æ•°
                if consecutive_failures >= max_failures:
                    print(f"âš ï¸  è¿ç»­{max_failures}æ¬¡è·å–æ•°æ®å¤±è´¥ï¼Œå°è¯•é‡æ–°è¿æ¥...")
                    self.sensor_reader.disconnect()
                    time.sleep(1)
                    if self.sensor_reader.connect():
                        consecutive_failures = 0
                        print(f"âœ… é‡æ–°è¿æ¥æˆåŠŸ")
                    else:
                        print(f"âŒ é‡æ–°è¿æ¥å¤±è´¥")
                        break
                
                # çŸ­æš‚ä¼‘çœ 
                time.sleep(0.001)
                
            except Exception as e:
                print(f"âŒ æ•°æ®é‡‡é›†é”™è¯¯: {e}")
                consecutive_failures += 1
                time.sleep(0.1)
        
        # æ¸…ç†
        self.sensor_reader.disconnect()
        print(f"ğŸ”Œ æ•°æ®é‡‡é›†çº¿ç¨‹å·²åœæ­¢")
    
    def prediction_processor(self):
        """é¢„æµ‹å¤„ç†çº¿ç¨‹"""
        print(f"ğŸ§  å¯åŠ¨é¢„æµ‹å¤„ç†çº¿ç¨‹...")
        
        # ç­‰å¾…æ¨¡å‹åŠ è½½
        while self.running and not self.model_loaded:
            print(f"â³ ç­‰å¾…æ¨¡å‹åŠ è½½...")
            time.sleep(1)
        
        if not self.model_loaded:
            print(f"âŒ æ¨¡å‹æœªåŠ è½½ï¼Œé¢„æµ‹çº¿ç¨‹é€€å‡º")
            return
        
        print(f"âœ… æ¨¡å‹å·²å°±ç»ªï¼Œå¼€å§‹å®æ—¶é¢„æµ‹...")
        
        while self.running:
            try:
                # ä»é˜Ÿåˆ—è·å–æ•°æ®
                timestamp, pressure_data = self.data_queue.get(timeout=1)
                
                # è½¬æ¢ä¸ºå›¾åƒæ ¼å¼
                image = pressure_to_image(pressure_data)
                image = image[np.newaxis, ..., np.newaxis]  # æ·»åŠ batchå’Œchannelç»´åº¦
                
                # è¿›è¡Œé¢„æµ‹
                prediction = self.model.predict(image, verbose=0)
                predicted_class = np.argmax(prediction[0])
                confidence = prediction[0][predicted_class]
                predicted_label = self.class_names[predicted_class]
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self.stats['total_samples'] += 1
                self.stats['predictions'][predicted_label] += 1
                self.stats['last_result'] = {
                    'timestamp': timestamp,
                    'label': predicted_label,
                    'confidence': confidence,
                    'probabilities': prediction[0],
                    'data_stats': {
                        'min': pressure_data.min(),
                        'max': pressure_data.max(),
                        'mean': pressure_data.mean(),
                        'non_zero': np.count_nonzero(pressure_data)
                    }
                }
                self.stats['confidence_history'].append(confidence)
                
                # å°†ç»“æœæ”¾å…¥ç»“æœé˜Ÿåˆ—
                if not self.result_queue.full():
                    self.result_queue.put(self.stats['last_result'])
                
            except queue.Empty:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                continue
            except Exception as e:
                print(f"âŒ é¢„æµ‹å¤„ç†é”™è¯¯: {e}")
                time.sleep(0.1)
        
        print(f"ğŸ§  é¢„æµ‹å¤„ç†çº¿ç¨‹å·²åœæ­¢")
    
    def display_results(self, update_interval=0.5):
        """æ˜¾ç¤ºå®æ—¶ç»“æœ"""
        print(f"ğŸ“Š å¯åŠ¨ç»“æœæ˜¾ç¤º...")
        print(f"=" * 80)
        print(f"å®æ—¶å‹åŠ›ä¼ æ„Ÿå™¨çŠ¶æ€æ£€æµ‹ç³»ç»Ÿ")
        print(f"æŒ‰ Ctrl+C åœæ­¢æ£€æµ‹")
        print(f"=" * 80)
        
        last_display = 0
        
        while self.running:
            try:
                current_time = time.time()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°ç»“æœ
                try:
                    result = self.result_queue.get_nowait()
                    
                    # å®æ—¶æ˜¾ç¤ºæ¯ä¸ªé¢„æµ‹ç»“æœ
                    timestamp = result['timestamp'].strftime('%H:%M:%S.%f')[:-3]
                    label = result['label']
                    confidence = result['confidence']
                    
                    # æ ¹æ®ç½®ä¿¡åº¦æ˜¾ç¤ºä¸åŒçš„æŒ‡ç¤ºç¬¦
                    if confidence > 0.8:
                        indicator = "ğŸŸ¢"  # é«˜ç½®ä¿¡åº¦
                    elif confidence > 0.6:
                        indicator = "ğŸŸ¡"  # ä¸­ç­‰ç½®ä¿¡åº¦
                    else:
                        indicator = "ğŸ”´"  # ä½ç½®ä¿¡åº¦
                    
                    # çŠ¶æ€æ˜ å°„åˆ°ä¸­æ–‡
                    status_map = {'left': 'å·¦å', 'normal': 'æ­£å¸¸', 'right': 'å³å'}
                    status_cn = status_map.get(label, label)
                    
                    print(f"[{timestamp}] {indicator} æ£€æµ‹ç»“æœ: {status_cn:4s} | ç½®ä¿¡åº¦: {confidence:.3f} | "
                          f"æ•°æ®èŒƒå›´: {result['data_stats']['min']}-{result['data_stats']['max']}")
                
                except queue.Empty:
                    pass
                
                # å®šæœŸæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                if current_time - last_display > update_interval * 10:  # æ¯5ç§’æ˜¾ç¤ºä¸€æ¬¡ç»Ÿè®¡
                    self.display_statistics()
                    last_display = current_time
                
                time.sleep(0.1)
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"âŒ æ˜¾ç¤ºé”™è¯¯: {e}")
                time.sleep(0.1)
    
    def display_statistics(self):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        if self.stats['total_samples'] == 0:
            return
        
        print(f"\n" + "â”€" * 60)
        print(f"ğŸ“ˆ å®æ—¶ç»Ÿè®¡ (æ€»æ ·æœ¬: {self.stats['total_samples']})")
        
        # é¢„æµ‹åˆ†å¸ƒ
        total = sum(self.stats['predictions'].values())
        if total > 0:
            for label, count in self.stats['predictions'].items():
                percentage = count / total * 100
                status_cn = {'left': 'å·¦å', 'normal': 'æ­£å¸¸', 'right': 'å³å'}[label]
                print(f"   {status_cn}: {count:4d} ({percentage:5.1f}%)")
        
        # æœ€è¿‘çš„ç½®ä¿¡åº¦
        if self.stats['confidence_history']:
            avg_confidence = np.mean(self.stats['confidence_history'])
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        
        # è¿è¡Œæ—¶é—´
        if self.stats['start_time']:
            elapsed = time.time() - self.stats['start_time']
            rate = self.stats['total_samples'] / elapsed if elapsed > 0 else 0
            print(f"   æ£€æµ‹é€Ÿç‡: {rate:.1f} æ ·æœ¬/ç§’")
        
        print(f"â”€" * 60)
    
    def start(self):
        """å¯åŠ¨å®æ—¶æ£€æµ‹"""
        print(f"ğŸš€ å¯åŠ¨å®æ—¶å‹åŠ›ä¼ æ„Ÿå™¨æ£€æµ‹ç³»ç»Ÿ...")
        
        # è®¾ç½®å¼€å§‹æ—¶é—´
        self.stats['start_time'] = time.time()
        self.running = True
        
        # å¼‚æ­¥åŠ è½½æ¨¡å‹
        model_thread = self.load_model_async()
        
        # å¯åŠ¨æ•°æ®é‡‡é›†çº¿ç¨‹
        self.sensor_thread = threading.Thread(target=self.sensor_data_collector, daemon=True)
        self.sensor_thread.start()
        
        # å¯åŠ¨é¢„æµ‹å¤„ç†çº¿ç¨‹
        self.detector_thread = threading.Thread(target=self.prediction_processor, daemon=True)
        self.detector_thread.start()
        
        try:
            # ä¸»çº¿ç¨‹æ˜¾ç¤ºç»“æœ
            self.display_results()
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸  ç”¨æˆ·åœæ­¢æ£€æµ‹")
        finally:
            self.stop()
    
    def stop(self):
        """åœæ­¢æ£€æµ‹"""
        print(f"\nğŸ›‘ æ­£åœ¨åœæ­¢æ£€æµ‹ç³»ç»Ÿ...")
        self.running = False
        
        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if self.sensor_thread and self.sensor_thread.is_alive():
            self.sensor_thread.join(timeout=3)
        
        if self.detector_thread and self.detector_thread.is_alive():
            self.detector_thread.join(timeout=3)
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        print(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
        self.display_statistics()
        
        print(f"âœ… æ£€æµ‹ç³»ç»Ÿå·²åœæ­¢")

class SimpleRealTimeDetector:
    """ç®€åŒ–ç‰ˆå®æ—¶æ£€æµ‹å™¨ï¼ˆå•çº¿ç¨‹ï¼‰"""
    
    def __init__(self, model_path='../models/cnn_augmented_model.keras'):
        self.model_path = model_path
        self.model = None
        self.class_names = ['left', 'normal', 'right']
        self.sensor_reader = PressureSensorReader()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_samples': 0,
            'predictions': {'left': 0, 'normal': 0, 'right': 0},
            'start_time': time.time()
        }
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        print(f"ğŸ”„ åŠ è½½æ¨¡å‹: {self.model_path}")
        try:
            self.model = keras.models.load_model(self.model_path)
            print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
            return True
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def run_simple_detection(self, max_samples=100):
        """è¿è¡Œç®€åŒ–æ£€æµ‹"""
        print(f"ğŸš€ å¯åŠ¨ç®€åŒ–å®æ—¶æ£€æµ‹ (æœ€å¤š{max_samples}ä¸ªæ ·æœ¬)...")
        
        # åŠ è½½æ¨¡å‹
        if not self.load_model():
            return
        
        # è¿æ¥ä¼ æ„Ÿå™¨
        if not self.sensor_reader.connect():
            print(f"âŒ ä¼ æ„Ÿå™¨è¿æ¥å¤±è´¥")
            return
        
        print(f"âœ… å¼€å§‹å®æ—¶æ£€æµ‹...")
        print(f"æŒ‰ Ctrl+C åœæ­¢")
        print(f"=" * 70)
        
        try:
            # ç­‰å¾…è¿æ¥ç¨³å®š
            time.sleep(2)
            self.sensor_reader.serial_conn.flushInput()
            self.sensor_reader.serial_conn.flushOutput()
            
            sample_count = 0
            
            while sample_count < max_samples:
                # è¯»å–æ•°æ®
                raw_data = self.sensor_reader.read_raw_data(512)
                
                if raw_data:
                    frames = self.sensor_reader.parse_hex_data(raw_data)
                    
                    if frames:
                        for frame in frames:
                            sample_count += 1
                            
                            # è½¬æ¢ä¸ºå›¾åƒå¹¶é¢„æµ‹
                            image = pressure_to_image(frame)
                            image = image[np.newaxis, ..., np.newaxis]
                            
                            prediction = self.model.predict(image, verbose=0)
                            predicted_class = np.argmax(prediction[0])
                            confidence = prediction[0][predicted_class]
                            predicted_label = self.class_names[predicted_class]
                            
                            # æ›´æ–°ç»Ÿè®¡
                            self.stats['total_samples'] += 1
                            self.stats['predictions'][predicted_label] += 1
                            
                            # æ˜¾ç¤ºç»“æœ
                            timestamp = datetime.now().strftime('%H:%M:%S')
                            status_map = {'left': 'å·¦å', 'normal': 'æ­£å¸¸', 'right': 'å³å'}
                            status_cn = status_map[predicted_label]
                            
                            if confidence > 0.8:
                                indicator = "ğŸŸ¢"
                            elif confidence > 0.6:
                                indicator = "ğŸŸ¡"
                            else:
                                indicator = "ğŸ”´"
                            
                            print(f"[{timestamp}] {indicator} æ ·æœ¬{sample_count:3d}: {status_cn} "
                                  f"(ç½®ä¿¡åº¦: {confidence:.3f}) | "
                                  f"æ•°æ®: {frame.min()}-{frame.max()}")
                            
                            if sample_count >= max_samples:
                                break
                
                time.sleep(0.01)
        
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸  ç”¨æˆ·åœæ­¢æ£€æµ‹")
        finally:
            self.sensor_reader.disconnect()
            
            # æ˜¾ç¤ºç»Ÿè®¡
            print(f"\nğŸ“Š æ£€æµ‹å®Œæˆç»Ÿè®¡:")
            total = sum(self.stats['predictions'].values())
            for label, count in self.stats['predictions'].items():
                status_cn = {'left': 'å·¦å', 'normal': 'æ­£å¸¸', 'right': 'å³å'}[label]
                percentage = count / total * 100 if total > 0 else 0
                print(f"   {status_cn}: {count} æ¬¡ ({percentage:.1f}%)")
            
            elapsed = time.time() - self.stats['start_time']
            rate = total / elapsed if elapsed > 0 else 0
            print(f"   æ£€æµ‹é€Ÿç‡: {rate:.1f} æ ·æœ¬/ç§’")

def test_model_only():
    """ä»…æµ‹è¯•æ¨¡å‹åŠ è½½å’Œé¢„æµ‹åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•æ¨¡å‹åŠŸèƒ½...")
    
    # åŠ è½½æ¨¡å‹
    model_path = '../models/cnn_augmented_model.keras'
    try:
        model = keras.models.load_model(model_path)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    test_data = np.random.randint(0, 1000, (3, 256))
    class_names = ['left', 'normal', 'right']
    
    print(f"ğŸ”® æµ‹è¯•é¢„æµ‹...")
    for i, data in enumerate(test_data):
        image = pressure_to_image(data)
        image = image[np.newaxis, ..., np.newaxis]
        
        prediction = model.predict(image, verbose=0)
        predicted_class = np.argmax(prediction[0])
        confidence = prediction[0][predicted_class]
        predicted_label = class_names[predicted_class]
        
        print(f"   æµ‹è¯•æ ·æœ¬{i+1}: {predicted_label} (ç½®ä¿¡åº¦: {confidence:.3f})")
    
    print(f"âœ… æ¨¡å‹æµ‹è¯•å®Œæˆ")

def demo_with_saved_data():
    """ä½¿ç”¨ä¿å­˜çš„æ•°æ®è¿›è¡Œæ¼”ç¤º"""
    print("ğŸ¬ ä½¿ç”¨ä¿å­˜æ•°æ®è¿›è¡Œæ¼”ç¤º...")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„æµ‹è¯•æ•°æ®
    test_files = ['test_quick.csv', '../data/test_quick.csv', 'real_time_data.csv']
    data_file = None
    
    for file in test_files:
        if os.path.exists(file):
            data_file = file
            break
    
    if not data_file:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯•æ•°æ®æ–‡ä»¶")
        return
    
    print(f"ğŸ“‚ ä½¿ç”¨æ•°æ®æ–‡ä»¶: {data_file}")
    
    # åŠ è½½æ¨¡å‹
    model_path = '../models/cnn_augmented_model.keras'
    try:
        model = keras.models.load_model(model_path)
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return
    
    # åŠ è½½æ•°æ®
    try:
        import pandas as pd
        df = pd.read_csv(data_file)
        features = df.values
        print(f"ğŸ“Š åŠ è½½äº† {len(features)} ä¸ªæ ·æœ¬")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # æ¨¡æ‹Ÿå®æ—¶æ£€æµ‹
    print(f"ğŸ® å¼€å§‹æ¨¡æ‹Ÿå®æ—¶æ£€æµ‹...")
    print(f"=" * 60)
    
    class_names = ['left', 'normal', 'right']
    stats = {'left': 0, 'normal': 0, 'right': 0}
    
    for i, data in enumerate(features):
        # é¢„æµ‹
        image = pressure_to_image(data)
        image = image[np.newaxis, ..., np.newaxis]
        
        prediction = model.predict(image, verbose=0)
        predicted_class = np.argmax(prediction[0])
        confidence = prediction[0][predicted_class]
        predicted_label = class_names[predicted_class]
        
        stats[predicted_label] += 1
        
        # æ˜¾ç¤ºç»“æœ
        timestamp = datetime.now().strftime('%H:%M:%S')
        status_map = {'left': 'å·¦å', 'normal': 'æ­£å¸¸', 'right': 'å³å'}
        status_cn = status_map[predicted_label]
        
        if confidence > 0.8:
            indicator = "ğŸŸ¢"
        elif confidence > 0.6:
            indicator = "ğŸŸ¡"
        else:
            indicator = "ğŸ”´"
        
        print(f"[{timestamp}] {indicator} æ ·æœ¬{i+1:3d}: {status_cn} "
              f"(ç½®ä¿¡åº¦: {confidence:.3f}) | "
              f"æ•°æ®èŒƒå›´: {data.min()}-{data.max()}")
        
        # æ¨¡æ‹Ÿå®æ—¶é—´éš”
        time.sleep(0.2)
    
    # ç»Ÿè®¡ç»“æœ
    print(f"\nğŸ“ˆ æ¼”ç¤ºå®Œæˆç»Ÿè®¡:")
    total = sum(stats.values())
    for label, count in stats.items():
        status_cn = {'left': 'å·¦å', 'normal': 'æ­£å¸¸', 'right': 'å³å'}[label]
        percentage = count / total * 100 if total > 0 else 0
        print(f"   {status_cn}: {count} æ¬¡ ({percentage:.1f}%)")

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ğŸš€ å®æ—¶å‹åŠ›ä¼ æ„Ÿå™¨æ£€æµ‹ç³»ç»Ÿ")
        print("=" * 50)
        print("ğŸ“– ä½¿ç”¨æ–¹æ³•:")
        print("   python real_time_detector.py full              - å®Œæ•´å¤šçº¿ç¨‹å®æ—¶æ£€æµ‹")
        print("   python real_time_detector.py simple [æ•°é‡]      - ç®€åŒ–å•çº¿ç¨‹æ£€æµ‹")
        print("   python real_time_detector.py test              - æµ‹è¯•æ¨¡å‹åŠŸèƒ½")
        print("   python real_time_detector.py demo              - ä½¿ç”¨ä¿å­˜æ•°æ®æ¼”ç¤º")
        print("")
        print("ğŸ’¡ æ¨èä½¿ç”¨:")
        print("   python real_time_detector.py simple 20         - å¿«é€Ÿæ£€æµ‹20ä¸ªæ ·æœ¬")
        print("   python real_time_detector.py demo              - æŸ¥çœ‹æ¼”ç¤ºæ•ˆæœ")
        print("   python real_time_detector.py test              - éªŒè¯æ¨¡å‹çŠ¶æ€")
        return
    
    mode = sys.argv[1]
    
    if mode == 'full':
        # å®Œæ•´å¤šçº¿ç¨‹æ£€æµ‹
        detector = RealTimeDetector()
        detector.start()
        
    elif mode == 'simple':
        # ç®€åŒ–å•çº¿ç¨‹æ£€æµ‹
        max_samples = int(sys.argv[2]) if len(sys.argv) > 2 else 100
        detector = SimpleRealTimeDetector()
        detector.run_simple_detection(max_samples)
        
    elif mode == 'test':
        # æµ‹è¯•æ¨¡å‹åŠŸèƒ½
        test_model_only()
        
    elif mode == 'demo':
        # æ¼”ç¤ºæ¨¡å¼
        demo_with_saved_data()
        
    else:
        print(f"âŒ æœªçŸ¥æ¨¡å¼: {mode}")
        print(f"ä½¿ç”¨ 'python real_time_detector.py' æŸ¥çœ‹å¸®åŠ©")

if __name__ == "__main__":
    main()